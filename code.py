# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bsq--wVSFe_vileAA1O50TDousnqNWp-

# **Importing Libraries**
"""

from __future__ import print_function, division
from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Concatenate
from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Conv2DTranspose
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
from keras.models import load_model
from keras.applications.resnet50 import ResNet50
from keras.callbacks import EarlyStopping
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from numpy import asarray
import cv2
import os
from google.colab import files
import pickle
import random
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix

"""# **Task 1: Create Synthetic Covid-19 X-Ray Images with Conditional Generative Adversarial Networks**

## Subtask 1.1 - Building and training a cGAN

I have split this subtask into 3 different tasks; data preprocessing, building and training the cGAN model, and generating synthetic images. In each section below there is a short description/explanation of the code that was implemented for it.

### 1.1.1 - Data Preprocessing

In this section of Subtask 1.1, I upload the dataset .zip file 'DMV_Assess_1_Covid-19_Dataset' file to Google Colab. Then, I unzip the dataset file and loop through the images of each class directory. Each image is preprocessed and then added to a dictionary (data) containing the preprocessed image (X_train) and their label (y_train). The data in this dictionary will be used to train the cGAN model. Preprocessing includes;

*   Resizing images to a size of (128 x 128)
*   Normalizing images from [0, 255] to [-1, 1]
*   Expand images to 3D to include channel

#### Uploading the dataset
"""

# upload the dataset .zip file and then unzip the file - this may take a while
print("Please upload the dataset file named 'CS551G_DMV_Assessment_1_Dataset.zip'.\n")
files.upload()
!unzip /content/CS551G_DMV_Assessment_1_Dataset.zip

"""#### Preprocessing the dataset"""

# directory paths of images for both classes
xray_covid_path = 'DMV_Assess_1_Covid-19_Dataset/Covid-19'
xray_normal_path = 'DMV_Assess_1_Covid-19_Dataset/Normal'

# preprocesses all images in a given directory and returns the preprocessed images
def preprocess_images(path):
  prep_imgs = []  # preprocessed images
  width, height = 128, 128

  for filename in os.listdir(path):
      img = cv2.imread(path + '/' + filename, 0) # read grayscale image
      # resize image to size (128 x 128)
      img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)
      # normalize image between range -1 - 1
      img = (img.astype(np.float32) - 127.5) / 127.5
      # add a channel - from shape (128 x 128) to (128 x 128 x 1)
      img = img.reshape(width, height, 1)

      # add image to list of preprocessed images
      prep_imgs.append(img)
  return np.array(prep_imgs)

# get preprocessed images and assign them their correct class labels
xray_covid_imgs = preprocess_images(xray_covid_path)
xray_covid_lbls = np.full(shape=len(xray_covid_imgs), fill_value=1, dtype=np.int)
xray_normal_imgs = preprocess_images(xray_normal_path)
xray_normal_lbls = np.full(shape=len(xray_normal_imgs), fill_value=0, dtype=np.int)

# saving data to a dictionary
data = {
    'X_train': np.concatenate((xray_covid_imgs, xray_normal_imgs)),
    'y_train': np.concatenate((xray_covid_lbls, xray_normal_lbls))
}
# save to .pkl file
pickle.dump(data, open("preprocessed_data.pkl", "wb"))

print("A total of {} images and labels were preprocessed from the dataset.".format(len(data['X_train'])))

# visualizing four random images before and after preprocessing
xray_covid_filenames = os.listdir(xray_covid_path)
xray_normal_filenames = os.listdir(xray_normal_path)

fig = plt.figure(figsize=(15,5))

# plot two random covid x-ray images
for x in range(2):
    index = random.randint(0, 99)
    before_img = cv2.imread(xray_covid_path + '/' + xray_covid_filenames[index], 1)
    after_img = data['X_train'][index].reshape((128,128))
    plt.subplot(2, 4, 1 + x)
    plt.axis('off')
    plt.imshow(before_img)
    plt.subplot(2, 4, 5 + x)
    plt.axis('off')
    plt.imshow(after_img, cmap="gray")

# plot two random normal x-ray images
for x in range(2,4):
    index = random.randint(0, 99)
    before_img = cv2.imread(xray_normal_path + '/' + xray_normal_filenames[index], 1)
    after_img = data['X_train'][100+index].reshape((128,128))
    plt.subplot(2, 4, 1 + x)
    plt.axis('off')
    plt.imshow(before_img)
    plt.subplot(2, 4, 5 + x)
    plt.axis('off')
    plt.imshow(after_img, cmap="gray")

plt.subplots_adjust(hspace=0.5)
plt.figtext(0.5, 0.5, 'After Preprocessing', ha='center', va='center', size='large')
plt.figtext(0.5, 0.95, 'Original Image', ha='center', va='center', size='large')

plt.show()

"""### 1.1.2 - Building and training the cGAN model

In this section of Subtask 1.1, I build the architecture of the cGAN model and train it. I modified the 'CGAN' class that was provided in 'cgan.py' to be used with this dataset. Experimentation was carried out to determine which type of layers to use in the generator and discriminator models so that clearer images were made. The generator and discriminator uses Conv2DTranspose and Conv2D respectively instead of dense layers, as these were determined to yield clearer (less grainy) results. You can specify what **learning rate** (lr) you want to use when initializing the 'CGAN' class, and specify which **batch size**, **epochs** and **model name** to use when training the CGAN object.

The 'train()' function was also altered so that half batches (batch_size/2) were used instead of the batch size when training the discriminator, and the full batch size is only used for training the generator. **At the end of the function when training is complete, the generator model is saved to a file (model_name) which will be loaded in the future to generate any amount of images.**

In the 'Training the cGAN model' section, I train the final cGAN model using the best determined parameters from which were determined from subtask 1.2 later. The model is trained using a learning rate of 0.0002 (default), 500 epochs and batch size of 32. It should be noted that sample images are printed out every 20 epochs in the to monitor the models progress. Also, it should be noted that 500 epochs was used instead of 300 as this was seen carried out in research.

####  Building the cGAN model
"""

class CGAN():
    def __init__(self, data, lr=0.0002):
        self.img_rows = 128
        self.img_cols = 128
        self.channels = 1
        self.img_shape = (self.img_rows, self.img_cols, self.channels)
        self.num_classes = 2
        self.latent_dim = 100
        self.optimizer = Adam(lr, 0.5)
        self.X_train = data['X_train']
        self.y_train = data['y_train']

        self.discriminator = self.build_discriminator()
        self.generator = self.build_generator()
        self.discriminator.trainable = False

        noise, label = self.generator.input
        img = self.generator.output
        valid = self.discriminator([img, label])

        self.combined = Model([noise, label], valid)
        self.combined.compile(loss=['binary_crossentropy'], optimizer=self.optimizer)

    def build_generator(self):
        # parameters
        strides = 2 # stride to downsample (best practice)
        alpha = 0.2 # leaky relu slope/alpha (best practice)
        dropout = 0.4
        kernel_size = 4
        momentum = 0.8

        # conditional (generator)
        input_label = Input(shape=(1,), dtype='int32')
        label_embedding = Embedding(self.num_classes, self.latent_dim)(input_label)
        label_embedding = Dense(8*8)(label_embedding)
        label_embedding = Reshape((8, 8, 1))(label_embedding)

        input_noise = Input(shape=(self.latent_dim,))
        noise = LeakyReLU(alpha=alpha)(Dense(1024 * 8 * 8)(input_noise))
        noise = Reshape((8, 8, 1024))(noise)
        
        model_input = Concatenate()([noise, label_embedding])

        # generator
        model = Sequential()
        # upsample to 16x16
        model.add(Conv2DTranspose(1024, kernel_size, strides=strides, padding='same'))
        model.add(BatchNormalization(momentum=momentum))
        model.add(LeakyReLU(alpha=alpha))
        # upsample to 32x32
        model.add(Conv2DTranspose(512, kernel_size, strides=strides, padding='same'))
        model.add(BatchNormalization(momentum=momentum))
        model.add(LeakyReLU(alpha=alpha))
        # upsample to 64x64
        model.add(Conv2DTranspose(256, kernel_size, strides=strides, padding='same'))
        model.add(BatchNormalization(momentum=momentum))
        model.add(LeakyReLU(alpha=alpha))
        # # upsample to 128x128
        model.add(Conv2DTranspose(128, kernel_size, strides=strides, padding='same'))
        model.add(BatchNormalization(momentum=momentum))
        model.add(LeakyReLU(alpha=alpha))
        # output layer
        model.add(Conv2D(1, kernel_size, padding='same', activation='tanh'))
        
        output_img = model(model_input)
        model.summary()
        return Model([input_noise, input_label], output_img)

    def build_discriminator(self):
        # parameters
        strides = 2 # stride to downsample (best practice)
        alpha = 0.2 # leaky relu slope/alpha (best practice)
        dropout = 0.4
        kernel_size = 4

        # conditional (discriminator)
        input_image = Input(shape=self.img_shape)
        input_label = Input(shape=(1,), dtype='int32')
        label_embedding = Embedding(self.num_classes, 100)(input_label)
        label_embedding = Dense(self.img_shape[0]*self.img_shape[1])(label_embedding)
        label_embedding = Reshape(self.img_shape)(label_embedding)
        model_input = Concatenate()([input_image, label_embedding])

        # discriminator
        model = Sequential()
        # downsample to 64x64
        model.add(Conv2D(128, kernel_size, strides=strides, padding='same'))
        model.add(LeakyReLU(alpha=alpha))
        # downsample to 32x32
        model.add(Conv2D(256, kernel_size, strides=strides, padding='same'))
        model.add(LeakyReLU(alpha=alpha))
        # downsample to 16x16
        model.add(Conv2D(512, kernel_size, strides=strides, padding='same'))
        model.add(LeakyReLU(alpha=alpha))
        # downsample to 8x8
        model.add(Conv2D(1024, kernel_size, strides=strides, padding='same'))
        model.add(LeakyReLU(alpha=alpha))
        # output layer
        model.add(Flatten())
        model.add(Dropout(dropout))
        model.add(Dense(1, activation='sigmoid'))
      
        classification = model(model_input)
        model.summary()
        discriminator = Model([input_image, input_label], classification)
        discriminator.compile(loss=['binary_crossentropy'], optimizer=self.optimizer, metrics=['accuracy'])
        return discriminator
 

    # generate random noise (points in latent space) and integer class labels
    def generate_noise(self, n):
        # generate random points/noise and reshape into proper size
        noise = np.random.randn(self.latent_dim * n)
        noise = noise.reshape(n, self.latent_dim)
        # generate random labels
        labels = np.random.randint(0, self.num_classes, n)
        return [noise, labels]

    def train(self, epochs=100, batch_size=128, model_name='cgan_generator'):
        batch_per_ep = int(len(self.X_train)/batch_size)  # batches per epoch
        half_batch = int(batch_size/2) # half batch size for training discriminator

        valid = np.ones((half_batch, 1))
        fake = np.zeros((half_batch, 1))
        fake_full = np.ones((batch_size, 1)) # for fake samples

        for e in range(epochs):
              for b in range(batch_per_ep):
                  # ---------------------
                  #  Train Discriminator
                  # ---------------------
                  # select random half batch of 'real' images
                  idx = np.random.randint(0, self.X_train.shape[0], half_batch) # choose random instances
                  real_imgs, labels_real = self.X_train[idx], self.y_train[idx]  # select images and labels
                  # select half batch of 'fake' images
                  noise_fake, labels_fake = self.generate_noise(half_batch)
                  # generate a half batch of new images
                  gen_imgs = self.generator.predict([noise_fake, labels_fake])
                  
                  # update the discriminator model weights
                  d_loss_real = self.discriminator.train_on_batch([real_imgs, labels_real], valid)
                  d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels_fake], fake)
                  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

                  # ---------------------
                  #  Train Generator
                  # ---------------------
                  # get noise and random labels for generator
                  noise, labels = self.generate_noise(batch_size)
                  g_loss = self.combined.train_on_batch([noise, labels], fake_full)
              # summarize progress
              print("Epoch %d/%d Batch %d/%d [D loss: %.5f, acc: %.2f%%] [G loss: %.5f]" % (e+1, epochs, b+1, batch_per_ep, d_loss[0], 100*d_loss[1], g_loss))
              # save generated smaples at every x epochs
              if e % 20 == 0:
                  self.sample_images(e, model_name)
        # save the generator model for future use/evaluation          
        self.generator.save('models/'+model_name+'.h5')

    def sample_images(self, epoch, model_name):
        r, c = 2, 3
        # generate random noise and labels
        noise = np.random.normal(0, 1, (6, 100))
        sampled_labels = np.random.randint(0, self.num_classes, 6)
        # generate random noise and labels
        gen_imgs = self.generator.predict([noise, sampled_labels])
        gen_imgs = 0.5 * gen_imgs + 0.5  # rescale images 0 - 1

        fig, axs = plt.subplots(2, 3)
        cnt = 0
        for i in range(2):
            for j in range(3):
                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')
                axs[i,j].set_title("Covid: %d" % sampled_labels[cnt])
                axs[i,j].axis('off')
                cnt += 1
        fig.savefig("images/"+model_name+"/%d.png" % epoch)
        plt.show()
        plt.close()

"""#### Training the cGAN model"""

# load dictionary of preprocessed data
data = pickle.load(open("preprocessed_data.pkl", "rb"))

# example of training process
cgan = CGAN(data)  # learning rate 0.0002
cgan.train(500, 32, 'final_model')  # epochs 500 and batch size 32

"""### 1.1.3 - Generating synthetic images using pre-trained models

In this subsection of subtask 1.1, I create two functions 'generate_images' and 'plot_images' which generates images from a **pretrained generator model** and plots them for visualization. It should be noted that *r* and *c* refers to the *rows* and *columns* of the graph (a.k.a how many images you want). In this example I plotted 50 (5 x 10) images that were randomly generated from the model that was trained in the previous  (the final model).

I also made a code to generate two images (1 COVID and 1 Normal) using a pretrained model and compare it to a randomly selected image (1 COVID and 1 Normal) from the preprocessed dataset.
"""

def generate_images(model_name, r, c, title, latent_dim=100, num_classes=2):
    # load model
    model = load_model('models/'+model_name+'.h5')
    # generate random noise + labels
    noise = np.random.normal(0, 1, (r*c, 100))
    labels = np.random.randint(0, num_classes, r*c)
    # generate images
    imgs = model.predict([noise, labels])
    imgs = 0.5 * imgs + 0.5  # rescale images 0 - 1
    plot_images(imgs, labels, r, c, title) # visualize images

# create plot of generated images
def plot_images(imgs, labels, r, c, title):
    fig, axs = plt.subplots(r, c)
    fig.set_figheight(12)
    fig.set_figwidth(20)
    fig.suptitle(title, size=20, y=0.95)
    cnt = 0
    for i in range(r):
      for j in range(c):
        axs[i,j].imshow(imgs[cnt,:,:,0], cmap='gray')
        axs[i,j].set_title("Covid: %d" % labels[cnt])
        axs[i,j].axis('off')
        cnt += 1
    plt.show()
    plt.close()

# generate 50 images using pretrained model
generate_images('final_model', 5, 10, 'Example of 50 randomly generated images',)

def generate_images(model_name, r, c, title, latent_dim=100, num_classes=2):
    # load model
    model = load_model('models/'+model_name+'.h5')
    # generate random noise + labels
    noise = np.random.normal(0, 1, (r*c, 100))
    labels = np.array([0, 1])
    # generate images
    imgs = model.predict([noise, labels])
    imgs = 0.5 * imgs + 0.5  # rescale images 0 - 1
    print(imgs.shape)
    plot_images(imgs, labels, r, c, title) # visualize images

# create plot of generated images
def plot_images(imgs, labels, r, c, title):
    fig, axs = plt.subplots(r, c)
    fig.set_figheight(5)
    fig.set_figwidth(10)
    fig.suptitle(title, size=20, y=0.95)
    cnt = 0
    for j in range(c):
      axs[j].imshow(imgs[cnt,:,:,0], cmap='gray')
      axs[j].set_title("Covid: %d" % labels[cnt])
      axs[j].axis('off')
      cnt += 1
    plt.show()
    plt.close()

# generate 2 images COVID and NORMAL from pretrained model
generate_images('final_model', 1, 2, 'Fake Images',)
# choose random COVID and NORMAl image from dataset to compare
rc = random.choice(np.array(np.where(data['y_train'] == 1)).T)
rn = random.choice(np.array(np.where(data['y_train'] == 0)).T)
imgc = data['X_train'][rc[0]]
imgn = data['X_train'][rn[0]]
imgs = np.array([imgn, imgc])

imgs = 0.5 * imgs + 0.5  # rescale images 0 - 1
plot_images(imgs, np.array([0, 1]), 1, 2, "Real Images")

"""## Subtask 1.2 - Exploring different hyperparameters and outputting generated images

I have split this task into two different tasks as well; training and generating images. Below is the code containing the hyperparameters (params) which will be explored in the 'Training' section below. I will be exploring different epochs, batch sizes and learning rates. The code in the 'Training' section will create a model for each combination hyperparameters and save the trained model (and training images) to their respective folders. Then, the code in the 'Generating Images' will generate a Covid and Normal image for each trained model to be evaluated in the report.

Please note - **I had to split the 'Training' into three instances because the first part wasn't able to explore all the models as the runtime timed out (twice) in Colab.I also had to split the 'Generating Image' into three instances, because the page would crash due to an overload of memory (when all models are uploaded).**
"""

data = pickle.load(open("preprocessed_data.pkl", "rb"))

# hyperparameters to explore
params = {
    'epochs': [100, 200, 300],
    'batch_size': [16, 32, 64],
    'learning_rate': [0.002, 0.0002, 0.00002],
}

"""### 1.2.1 - Training (Part 1)"""

# build different models with different hyperparameters
for e in params['epochs']:
  for bs in params['batch_size']:
    for lr in params['learning_rate']:
      name = 'e_'+str(e)+'_bs_'+str(bs)+'_lr_'+str(lr) #create a model name
      os.mkdir('images/'+name)
      cgan = CGAN(data, lr) 
      cgan.train(e, bs, name)

"""### 1.2.1 - Training (Part 2)"""

# build only models for 300 epochs because runtime was disconnected
for e in [300]:
  for bs in params['batch_size']:
    for lr in params['learning_rate']:
      name = 'e_'+str(e)+'_bs_'+str(bs)+'_lr_'+str(lr) #create a model name
      os.mkdir('images/'+name)
      cgan = CGAN(data, lr)  
      cgan.train(e, bs, name)

"""### 1.2.1 - Training (Part 3)"""

# build only models for 300 epochs and bs 64 because runtime was disconnected (again)
for e in [300]:
  for bs in [64]:
    for lr in params['learning_rate']:
      name = 'e_'+str(e)+'_bs_'+str(bs)+'_lr_'+str(lr) #create a model name
      os.mkdir('images/'+name)
      cgan = CGAN(data, lr)  
      cgan.train(e, bs, name)

"""### 1.2.2 - Generating Images (Part 1)

"""

def generate_images(model_name, r, c, title, latent_dim=100, num_classes=2):
    # load model
    model = load_model('models/'+model_name+'.h5')
    # generate random noise + labels
    noise = np.random.normal(0, 1, (r*c, 100))
    labels = np.array([0,1])
    # generate images
    imgs = model.predict([noise, labels])
    imgs = 0.5 * imgs + 0.5  # rescale images 0 - 1
    plot_images(imgs, labels, r, c, title) # visualize images

# create plot of generated images
def plot_images(imgs, labels, r, c, title):
    fig, axs = plt.subplots(r, c)
    fig.set_figheight(5)
    fig.set_figwidth(10)
    fig.suptitle(title, size=20, y=0.95)
    cnt = 0
    for j in range(c):
      axs[j].imshow(imgs[cnt,:,:,0], cmap='gray')
      axs[j].set_title("Covid: %d" % labels[cnt])
      axs[j].axis('off')
      cnt += 1
    plt.show()
    plt.close()

# visualize generated images of different models with different hyperparameters
for e in [100]:
  for bs in params['batch_size']:
    for lr in params['learning_rate']:
      name = 'e_'+str(e)+'_bs_'+str(bs)+'_lr_'+str(lr) #create a model name
      title = 'E = ' + str(e) + '; BS = ' + str(bs) + '; LR = ' + str(lr)
      generate_images(name, 1, 2, title)

"""### 1.2.2 - Generating Images (Part 2)

"""

def generate_images(model_name, r, c, title, latent_dim=100, num_classes=2):
    # load model
    model = load_model('models/'+model_name+'.h5')
    # generate random noise + labels
    noise = np.random.normal(0, 1, (r*c, 100))
    labels = np.array([0,1])
    # generate images
    imgs = model.predict([noise, labels])
    imgs = 0.5 * imgs + 0.5  # rescale images 0 - 1
    plot_images(imgs, labels, r, c, title) # visualize images

# create plot of generated images
def plot_images(imgs, labels, r, c, title):
    fig, axs = plt.subplots(r, c)
    fig.set_figheight(5)
    fig.set_figwidth(10)
    fig.suptitle(title, size=20, y=0.95)
    cnt = 0
    for j in range(c):
      axs[j].imshow(imgs[cnt,:,:,0], cmap='gray')
      axs[j].set_title("Covid: %d" % labels[cnt])
      axs[j].axis('off')
      cnt += 1
    plt.show()
    plt.close()

# visualize generated images of different models with different hyperparameters
for e in [200]:
  for bs in params['batch_size']:
    for lr in params['learning_rate']:
      name = 'e_'+str(e)+'_bs_'+str(bs)+'_lr_'+str(lr) #create a model name
      title = 'E = ' + str(e) + '; BS = ' + str(bs) + '; LR = ' + str(lr)
      generate_images(name, 1, 2, title)

"""### 1.2.2 - Generating Images (Part 3)

"""

def generate_images(model_name, r, c, title, latent_dim=100, num_classes=2):
    # load model
    model = load_model('models/'+model_name+'.h5')
    # generate random noise + labels
    noise = np.random.normal(0, 1, (r*c, 100))
    labels = np.array([0,1])
    # generate images
    imgs = model.predict([noise, labels])
    imgs = 0.5 * imgs + 0.5  # rescale images 0 - 1
    plot_images(imgs, labels, r, c, title) # visualize images

# create plot of generated images
def plot_images(imgs, labels, r, c, title):
    fig, axs = plt.subplots(r, c)
    fig.set_figheight(5)
    fig.set_figwidth(10)
    fig.suptitle(title, size=20, y=0.95)
    cnt = 0
    for j in range(c):
      axs[j].imshow(imgs[cnt,:,:,0], cmap='gray')
      axs[j].set_title("Covid: %d" % labels[cnt])
      axs[j].axis('off')
      cnt += 1
    plt.show()
    plt.close()
    

# visualize generated images of different models with different hyperparameters
for e in [300]:
  for bs in params['batch_size']:
    for lr in params['learning_rate']:
      name = 'e_'+str(e)+'_bs_'+str(bs)+'_lr_'+str(lr) #create a model name
      title = 'E = ' + str(e) + '; BS = ' + str(bs) + '; LR = ' + str(lr)
      generate_images(name, 1, 2, title)

"""# **Task 2: Detect Covid-19 from Chest X-Ray Images using pre-trained networks**

In subtask 2.1, I created a script which loads a pretrained ResNet-50 model with imagenet weights and with the last fully connected layer removed (include_top=False). I then freeze the whole pretrained model (by settting all layers to trainable=False) and add a **flatten**, **dense**, **dropout** and another **dense** layer as a binary classifier to the end of the model. I split the dataset into 80% training and 20% training. I also used 10% of the training set as a validation set during training. I created a function 'plot_training_metrics' to illustrate the model's training and validation loss/accuracy. At the end of the script the model is evaluated using the test set, and a function 'plot_cf_and_classification' to display the confusion matrix and classification report (containing accuracy, and other metrics).

In subtask 2.2, I use the except same functions as subtask 2.1, however I manipulate the X_train values so that they include 50 randomly selected images of COVID labelled X-Ray images from the real dataset, 50 randomly generated images of COVID (using the best performing pretrained cGAN model from Subtask 1.2) images and 100 of the NORMAL labelled X-RAY images from the real dataset.

## Subtask 2.1 - Building a binary classification model using transfer learning
"""

def plot_training_metrics(history):
  # show training history and accuracy
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Training Accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')
  plt.show()

  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Training Loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')
  plt.show()

def plot_cf_and_classification(y_test, y_pred):
  # display confusion matrix and classification report
  df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), index = ['0','1'], columns = ['0','1'])
  df_cm.index.name = 'Actual'
  df_cm.columns.name = 'Predicted'
  plt.figure(figsize = (10,7))
  plt.suptitle("Confusion matrix")
  sns.set(font_scale=1.4) #for label size
  sns.heatmap(df_cm, cmap="Blues", annot=True, annot_kws={"size": 16}) # font size

  target_names = ['0', '1']
  print(classification_report(y_test, y_pred))

# load 100 COVID images and normal images (preprocessed)
data = pickle.load(open("preprocessed_data.pkl", "rb"))
X = data['X_train']
y = data['y_train']
X = np.repeat(X, 3, -1) # convert to 3-channel
# split data into 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, shuffle=True)

# load ResNet50 model with imagenet weight and remove last fully connected layer (include_top = False)
model = ResNet50(weights = 'imagenet', include_top=False, input_tensor=Input(shape=(128, 128, 3)))
model.summary()
# freeze whole pretrained model
for layer in model.layers:
  layer.trainable = False
last_layer = model.layers[-1].output  # get last layer from ResNet
# add two new trainable layers
new_layer = Flatten()(last_layer)
new_layer = Dense(1024, activation='relu')(new_layer)
new_layer = Dropout(0.2)(new_layer)
new_layer = Dense(1, activation='sigmoid')(new_layer)
# build and compile model
new_model = Model(model.input, new_layer)
new_model.compile(optimizer=Adam(lr=0.0002), loss='binary_crossentropy', metrics=['accuracy'])

# train new model
epochs = 20
batch_size = 16
callback = EarlyStopping(monitor='loss', patience=3)
history = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[callback], verbose=1, validation_split=0.1)
plot_training_metrics(history) # show training and validation scores

# evaluate new model
y_pred = new_model.predict(X_test)
y_pred = [1 * (x[0]>=0.5) for x in y_pred]
plot_cf_and_classification(y_test, y_pred)

"""## Subtask 2.2 - Repeat with 50 generated images"""

# load 100 COVID images and normal images (preprocessed)
data = pickle.load(open("preprocessed_data.pkl", "rb"))
X = data['X_train']
y = data['y_train']

# ---------- select 50 random COVID images from X ----------
X_normal_only = [x for i, x in enumerate(X) if y[i] == 0]
X_covid_only = [x for i, x in enumerate(X) if y[i] == 1]
X_half_covid_only = random.sample(X_covid_only, 50) # randomly select 50 COVID images

# ---------- generate 50 random COVID images ---------------
model_name = 'final_model'
model = load_model('models/'+model_name+'.h5')
# generate random noise + labels
noise = np.random.normal(0, 1, (50, 100))
labels = np.ones((50, 1)) # only covid labels
# generate 50 random COVID images
gen_imgs = model.predict([noise, labels])

# combine 50 + 50 COVID images and add to 100 normal images and set appropriate labels
X_covid_only = np.concatenate((X_half_covid_only, gen_imgs))
X = np.concatenate((X_normal_only, X_covid_only))
y = np.concatenate((np.zeros(100), np.ones(100)))

# ------------------------------------------------------------
# --------------- (SAME AS BEFORE) ---------------------------
# ------------------------------------------------------------
X = np.repeat(X, 3, -1) # convert to 3-channel
# split data into 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, shuffle=True)

# load ResNet50 model with imagenet weight and remove last fully connected layer (include_top = False)
model = ResNet50(weights = 'imagenet', include_top=False, input_tensor=Input(shape=(128, 128, 3)))
model.summary()
# freeze whole pretrained model
for layer in model.layers:
  layer.trainable = False
last_layer = model.layers[-1].output  # get last layer from ResNet
# add two new trainable layers
new_layer = Flatten()(last_layer)
new_layer = Dense(1024, activation='relu')(new_layer)
new_layer = Dropout(0.2)(new_layer)
new_layer = Dense(1, activation='sigmoid')(new_layer)
# build and compile model
new_model = Model(model.input, new_layer)
new_model.compile(optimizer=Adam(lr=0.0002), loss='binary_crossentropy', metrics=['accuracy'])

# train new model
epochs = 20
batch_size = 16
callback = EarlyStopping(monitor='loss', patience=3)
history = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[callback], verbose=1, validation_split=0.1)
plot_training_metrics(history) # show training and validation scores

# evaluate new model
y_pred = new_model.predict(X_test)
y_pred = [1 * (x[0]>=0.5) for x in y_pred]
plot_cf_and_classification(y_test, y_pred)